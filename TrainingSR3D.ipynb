{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiss0212/Super_resolution_3D_Model-/blob/main/TrainingSR3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wiss0212/Super_resolution_3D_Model-.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6BNRUPXphuS",
        "outputId": "f8b3f411-a66b-480a-f90b-9ed5fbbcfd90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Super_resolution_3D_Model-'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxzolIQ9oZFI",
        "outputId": "6d9408a2-827d-4a0a-b3dc-0daba5681f89"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, None, None, None, 64)\n",
            "(None, None, None, None, 64)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input0 (InputLayer)            [(None, None, None,  0           []                               \n",
            "                                 None, 1)]                                                        \n",
            "                                                                                                  \n",
            " initial_patches (Conv3D)       (None, None, None,   1792        ['input0[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " initial_patch_acti (Activation  (None, None, None,   0          ['initial_patches[0][0]']        \n",
            " )                              None, 64)                                                         \n",
            "                                                                                                  \n",
            " proj_coef (Hamiltonian_Conv3D)  (None, None, None,   112320     ['initial_patch_acti[0][0]']     \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv1 (Conv3D)                 (None, None, None,   110592      ['proj_coef[0][0]']              \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn2 (BatchNormalization)       (None, None, None,   256         ['conv1[0][0]']                  \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv3 (Conv3D)                 (None, None, None,   110592      ['bn2[0][0]']                    \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn4 (BatchNormalization)       (None, None, None,   256         ['conv3[0][0]']                  \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv5 (Conv3D)                 (None, None, None,   110592      ['bn4[0][0]']                    \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn6 (BatchNormalization)       (None, None, None,   256         ['conv5[0][0]']                  \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv7 (Conv3D)                 (None, None, None,   110592      ['bn6[0][0]']                    \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn8 (BatchNormalization)       (None, None, None,   256         ['conv7[0][0]']                  \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv9 (Conv3D)                 (None, None, None,   110592      ['bn8[0][0]']                    \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn10 (BatchNormalization)      (None, None, None,   256         ['conv9[0][0]']                  \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv11 (Conv3D)                (None, None, None,   110592      ['bn10[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn12 (BatchNormalization)      (None, None, None,   256         ['conv11[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv13 (Conv3D)                (None, None, None,   110592      ['bn12[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn14 (BatchNormalization)      (None, None, None,   256         ['conv13[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv15 (Conv3D)                (None, None, None,   110592      ['bn14[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn16 (BatchNormalization)      (None, None, None,   256         ['conv15[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv17 (Conv3D)                (None, None, None,   110592      ['bn16[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn18 (BatchNormalization)      (None, None, None,   256         ['conv17[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv19 (Conv3D)                (None, None, None,   110592      ['bn18[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn20 (BatchNormalization)      (None, None, None,   256         ['conv19[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv21 (Conv3D)                (None, None, None,   110592      ['bn20[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn22 (BatchNormalization)      (None, None, None,   256         ['conv21[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv23 (Conv3D)                (None, None, None,   110592      ['bn22[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn24 (BatchNormalization)      (None, None, None,   256         ['conv23[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv25 (Conv3D)                (None, None, None,   110592      ['bn24[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn26 (BatchNormalization)      (None, None, None,   256         ['conv25[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv27 (Conv3D)                (None, None, None,   110592      ['bn26[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn28 (BatchNormalization)      (None, None, None,   256         ['conv27[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv29 (Conv3D)                (None, None, None,   110592      ['bn28[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn30 (BatchNormalization)      (None, None, None,   256         ['conv29[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv31 (Conv3D)                (None, None, None,   110592      ['bn30[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn32 (BatchNormalization)      (None, None, None,   256         ['conv31[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv33 (Conv3D)                (None, None, None,   110592      ['bn32[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn34 (BatchNormalization)      (None, None, None,   256         ['conv33[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv35 (Conv3D)                (None, None, None,   110592      ['bn34[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn36 (BatchNormalization)      (None, None, None,   256         ['conv35[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv37 (Conv3D)                (None, None, None,   110592      ['bn36[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn38 (BatchNormalization)      (None, None, None,   256         ['conv37[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv39 (Conv3D)                (None, None, None,   110592      ['bn38[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn40 (BatchNormalization)      (None, None, None,   256         ['conv39[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv41 (Conv3D)                (None, None, None,   110592      ['bn40[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn42 (BatchNormalization)      (None, None, None,   256         ['conv41[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv43 (Conv3D)                (None, None, None,   110592      ['bn42[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn44 (BatchNormalization)      (None, None, None,   256         ['conv43[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv45 (Conv3D)                (None, None, None,   110592      ['bn44[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn46 (BatchNormalization)      (None, None, None,   256         ['conv45[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv47 (Conv3D)                (None, None, None,   110592      ['bn46[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn48 (BatchNormalization)      (None, None, None,   256         ['conv47[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv49 (Conv3D)                (None, None, None,   110592      ['bn48[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn50 (BatchNormalization)      (None, None, None,   256         ['conv49[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv51 (Conv3D)                (None, None, None,   110592      ['bn50[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn52 (BatchNormalization)      (None, None, None,   256         ['conv51[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv53 (Conv3D)                (None, None, None,   110592      ['bn52[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn54 (BatchNormalization)      (None, None, None,   256         ['conv53[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv55 (Conv3D)                (None, None, None,   110592      ['bn54[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn56 (BatchNormalization)      (None, None, None,   256         ['conv55[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv57 (Conv3D)                (None, None, None,   110592      ['bn56[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn58 (BatchNormalization)      (None, None, None,   256         ['conv57[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " conv59 (Conv3D)                (None, None, None,   110592      ['bn58[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " bn60 (BatchNormalization)      (None, None, None,   256         ['conv59[0][0]']                 \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " Thresholding60 (Activation)    (None, None, None,   0           ['bn60[0][0]']                   \n",
            "                                None, 64)                                                         \n",
            "                                                                                                  \n",
            " inv_trans (Conv3D)             (None, None, None,   1728        ['Thresholding60[0][0]']         \n",
            "                                None, 1)                                                          \n",
            "                                                                                                  \n",
            " subtract (Subtract)            (None, None, None,   0           ['input0[0][0]',                 \n",
            "                                None, 1)                          'inv_trans[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,441,280\n",
            "Trainable params: 3,437,440\n",
            "Non-trainable params: 3,840\n",
            "__________________________________________________________________________________________________\n",
            "resuming by loading epoch 050\n",
            "(None, None, None, None, 64)\n",
            "(None, None, None, None, 64)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-23 17:11:28: load trained model architecture\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "2023-05-23 17:12:01: current learning rate is 0.00000050\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 111s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1001 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0633 - sum_squared_error: 4327.7173 - lr: 5.0000e-07\n",
            "2023-05-23 17:13:52: current learning rate is 0.00000020\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1003 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0633 - sum_squared_error: 4344.3232 - lr: 2.0000e-07\n",
            "2023-05-23 17:15:14: current learning rate is 0.00000020\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0102 - mean_squared_error: 0.0102 - root_mean_squared_error: 0.1012 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0644 - sum_squared_error: 4422.4902 - lr: 2.0000e-07\n",
            "2023-05-23 17:16:37: current learning rate is 0.00000020\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0102 - mean_squared_error: 0.0102 - root_mean_squared_error: 0.1012 - mean_squared_logarithmic_error: 0.0045 - mean_absolute_error: 0.0639 - sum_squared_error: 4425.9951 - lr: 2.0000e-07\n",
            "2023-05-23 17:17:59: current learning rate is 0.00000020\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0997 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0629 - sum_squared_error: 4297.4043 - lr: 2.0000e-07\n",
            "2023-05-23 17:19:22: current learning rate is 0.00000020\n",
            "Epoch 56/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 89s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1007 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0636 - sum_squared_error: 4380.9126 - lr: 2.0000e-07\n",
            "2023-05-23 17:20:51: current learning rate is 0.00000020\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1003 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0632 - sum_squared_error: 4342.1846 - lr: 2.0000e-07\n",
            "2023-05-23 17:22:14: current learning rate is 0.00000020\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1001 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0633 - sum_squared_error: 4332.3721 - lr: 2.0000e-07\n",
            "2023-05-23 17:23:36: current learning rate is 0.00000020\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0103 - mean_squared_error: 0.0103 - root_mean_squared_error: 0.1014 - mean_squared_logarithmic_error: 0.0045 - mean_absolute_error: 0.0639 - sum_squared_error: 4446.0405 - lr: 2.0000e-07\n",
            "2023-05-23 17:24:59: current learning rate is 0.00000020\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0998 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0630 - sum_squared_error: 4306.2417\n",
            "Epoch 60: saving model to /content/drive/MyDrive/Colab Notebooks/models/DIVA3D_CBCT_SR2/model_060.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0998 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0630 - sum_squared_error: 4306.2417 - lr: 2.0000e-07\n",
            "2023-05-23 17:26:22: current learning rate is 0.00000020\n",
            "Epoch 61/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 88s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0990 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0625 - sum_squared_error: 4235.0957 - lr: 2.0000e-07\n",
            "2023-05-23 17:27:50: current learning rate is 0.00000010\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0989 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0624 - sum_squared_error: 4229.1050 - lr: 1.0000e-07\n",
            "2023-05-23 17:29:13: current learning rate is 0.00000010\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0996 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0630 - sum_squared_error: 4288.4717 - lr: 1.0000e-07\n",
            "2023-05-23 17:30:35: current learning rate is 0.00000010\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0990 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0624 - sum_squared_error: 4231.8755 - lr: 1.0000e-07\n",
            "2023-05-23 17:31:58: current learning rate is 0.00000010\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0990 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0624 - sum_squared_error: 4235.6172 - lr: 1.0000e-07\n",
            "2023-05-23 17:33:20: current learning rate is 0.00000010\n",
            "Epoch 66/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 90s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0999 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0629 - sum_squared_error: 4309.3340 - lr: 1.0000e-07\n",
            "2023-05-23 17:34:50: current learning rate is 0.00000010\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1000 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0630 - sum_squared_error: 4317.1880 - lr: 1.0000e-07\n",
            "2023-05-23 17:36:12: current learning rate is 0.00000010\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0992 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0624 - sum_squared_error: 4248.1274 - lr: 1.0000e-07\n",
            "2023-05-23 17:37:35: current learning rate is 0.00000010\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0998 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0633 - sum_squared_error: 4306.6602 - lr: 1.0000e-07\n",
            "2023-05-23 17:38:57: current learning rate is 0.00000010\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0999 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0632 - sum_squared_error: 4310.5269\n",
            "Epoch 70: saving model to /content/drive/MyDrive/Colab Notebooks/models/DIVA3D_CBCT_SR2/model_070.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0999 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0632 - sum_squared_error: 4310.5269 - lr: 1.0000e-07\n",
            "2023-05-23 17:40:21: current learning rate is 0.00000010\n",
            "Epoch 71/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 89s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0998 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0631 - sum_squared_error: 4302.3735 - lr: 1.0000e-07\n",
            "2023-05-23 17:41:50: current learning rate is 0.00000005\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0999 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0633 - sum_squared_error: 4310.5933 - lr: 5.0000e-08\n",
            "2023-05-23 17:43:13: current learning rate is 0.00000005\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0102 - mean_squared_error: 0.0102 - root_mean_squared_error: 0.1009 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0639 - sum_squared_error: 4394.3608 - lr: 5.0000e-08\n",
            "2023-05-23 17:44:35: current learning rate is 0.00000005\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1007 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0637 - sum_squared_error: 4380.4922 - lr: 5.0000e-08\n",
            "2023-05-23 17:45:58: current learning rate is 0.00000005\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1003 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0636 - sum_squared_error: 4347.1982 - lr: 5.0000e-08\n",
            "2023-05-23 17:47:20: current learning rate is 0.00000005\n",
            "Epoch 76/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 89s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0989 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0620 - sum_squared_error: 4225.4727 - lr: 5.0000e-08\n",
            "2023-05-23 17:48:49: current learning rate is 0.00000005\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1000 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0630 - sum_squared_error: 4321.1079 - lr: 5.0000e-08\n",
            "2023-05-23 17:50:11: current learning rate is 0.00000005\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0988 - mean_squared_logarithmic_error: 0.0042 - mean_absolute_error: 0.0620 - sum_squared_error: 4219.3945 - lr: 5.0000e-08\n",
            "2023-05-23 17:51:34: current learning rate is 0.00000005\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1006 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0638 - sum_squared_error: 4373.3511 - lr: 5.0000e-08\n",
            "2023-05-23 17:52:56: current learning rate is 0.00000005\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0997 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0630 - sum_squared_error: 4297.2808\n",
            "Epoch 80: saving model to /content/drive/MyDrive/Colab Notebooks/models/DIVA3D_CBCT_SR2/model_080.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0997 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0630 - sum_squared_error: 4297.2808 - lr: 5.0000e-08\n",
            "2023-05-23 17:54:19: current learning rate is 0.00000005\n",
            "Epoch 81/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 91s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0999 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0628 - sum_squared_error: 4311.8462 - lr: 5.0000e-08\n",
            "2023-05-23 17:55:50: current learning rate is 0.00000002\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.0999 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0629 - sum_squared_error: 4313.5063 - lr: 2.0000e-08\n",
            "2023-05-23 17:57:13: current learning rate is 0.00000002\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1001 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0633 - sum_squared_error: 4329.3374 - lr: 2.0000e-08\n",
            "2023-05-23 17:58:35: current learning rate is 0.00000002\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1004 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0631 - sum_squared_error: 4352.7266 - lr: 2.0000e-08\n",
            "2023-05-23 17:59:58: current learning rate is 0.00000002\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1000 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0632 - sum_squared_error: 4319.6792 - lr: 2.0000e-08\n",
            "2023-05-23 18:01:20: current learning rate is 0.00000002\n",
            "Epoch 86/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 90s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0997 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0623 - sum_squared_error: 4295.5806 - lr: 2.0000e-08\n",
            "2023-05-23 18:02:50: current learning rate is 0.00000002\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0995 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0627 - sum_squared_error: 4274.0728 - lr: 2.0000e-08\n",
            "2023-05-23 18:04:13: current learning rate is 0.00000002\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0994 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0624 - sum_squared_error: 4264.6377 - lr: 2.0000e-08\n",
            "2023-05-23 18:05:35: current learning rate is 0.00000002\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0995 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0627 - sum_squared_error: 4274.9282 - lr: 2.0000e-08\n",
            "2023-05-23 18:06:57: current learning rate is 0.00000002\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1003 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0629 - sum_squared_error: 4343.9102\n",
            "Epoch 90: saving model to /content/drive/MyDrive/Colab Notebooks/models/DIVA3D_CBCT_SR2/model_090.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1003 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0629 - sum_squared_error: 4343.9102 - lr: 2.0000e-08\n",
            "2023-05-23 18:08:21: current learning rate is 0.00000002\n",
            "Epoch 91/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 89s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1002 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0630 - sum_squared_error: 4333.1309 - lr: 2.0000e-08\n",
            "2023-05-23 18:09:50: current learning rate is 0.00000002\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0097 - mean_squared_error: 0.0097 - root_mean_squared_error: 0.0985 - mean_squared_logarithmic_error: 0.0042 - mean_absolute_error: 0.0622 - sum_squared_error: 4195.3164 - lr: 2.0000e-08\n",
            "2023-05-23 18:11:12: current learning rate is 0.00000002\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0103 - mean_squared_error: 0.0103 - root_mean_squared_error: 0.1014 - mean_squared_logarithmic_error: 0.0045 - mean_absolute_error: 0.0636 - sum_squared_error: 4445.0581 - lr: 2.0000e-08\n",
            "2023-05-23 18:12:34: current learning rate is 0.00000002\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0997 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0631 - sum_squared_error: 4292.1226 - lr: 2.0000e-08\n",
            "2023-05-23 18:13:57: current learning rate is 0.00000002\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0098 - mean_squared_error: 0.0098 - root_mean_squared_error: 0.0991 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0628 - sum_squared_error: 4244.5474 - lr: 2.0000e-08\n",
            "2023-05-23 18:15:19: current learning rate is 0.00000002\n",
            "Epoch 96/100\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n",
            "50/50 [==============================] - 90s 2s/step - loss: 0.0101 - mean_squared_error: 0.0101 - root_mean_squared_error: 0.1005 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0634 - sum_squared_error: 4362.2231 - lr: 2.0000e-08\n",
            "2023-05-23 18:16:49: current learning rate is 0.00000002\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0102 - mean_squared_error: 0.0102 - root_mean_squared_error: 0.1009 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0636 - sum_squared_error: 4397.3784 - lr: 2.0000e-08\n",
            "2023-05-23 18:18:12: current learning rate is 0.00000002\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0995 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0624 - sum_squared_error: 4273.6216 - lr: 2.0000e-08\n",
            "2023-05-23 18:19:34: current learning rate is 0.00000002\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0099 - mean_squared_error: 0.0099 - root_mean_squared_error: 0.0994 - mean_squared_logarithmic_error: 0.0043 - mean_absolute_error: 0.0629 - sum_squared_error: 4271.2861 - lr: 2.0000e-08\n",
            "2023-05-23 18:20:57: current learning rate is 0.00000002\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1002 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0632 - sum_squared_error: 4340.4912\n",
            "Epoch 100: saving model to /content/drive/MyDrive/Colab Notebooks/models/DIVA3D_CBCT_SR2/model_100.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0100 - mean_squared_error: 0.0100 - root_mean_squared_error: 0.1002 - mean_squared_logarithmic_error: 0.0044 - mean_absolute_error: 0.0632 - sum_squared_error: 4340.4912 - lr: 2.0000e-08\n",
            "good dim = (200, 1, 60, 60, 60)\n",
            "^_^-training data finished-^_^\n",
            "bad dim = (200, 60, 60, 60, 1)\n",
            "(200, 60, 60, 60, 1)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import glob\n",
        "import cv2\n",
        "import PIL\n",
        "import re\n",
        "import os, glob, datetime\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from skimage.transform import rescale\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.layers import  Input,Conv3D, BatchNormalization,Activation,Subtract, Reshape,Lambda\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "#import data_generator as dg\n",
        "import tensorflow.keras.backend as K\n",
        "import skimage\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.transform import rescale, resize\n",
        "from skimage.io import imread, imsave\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "\n",
        "## Params\n",
        "parser = argparse.ArgumentParser(description='Keras DIVA3D')\n",
        "parser.add_argument('--model', default='DIVA3D', type=str, help='choose a type of model')\n",
        "parser.add_argument('--kernel_size', default=3, type=int, help='kernel size')\n",
        "parser.add_argument('--batch_size', default=12, type=int, help='batch size')\n",
        "parser.add_argument('--train_data', default='/content/drive/MyDrive/Colab Notebooks/DATA_3D/', type=str, help='path of train data')\n",
        "\n",
        "parser.add_argument('--epoch', default=500, type=int, help='number of train epoches')\n",
        "parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\n",
        "parser.add_argument('--save_every', default=1, type=int, help='save model at every x epoches')\n",
        "parser.add_argument('-f', '--file', required=False)\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "kernel_size = args.kernel_size\n",
        "batch_size = args.batch_size\n",
        "\n",
        "save_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/models', args.model+'_'\n",
        "                        + 'CBCT_SR3')   # + str(sigma)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "     print(\"save_dir\",save_dir)\n",
        "     os.mkdir(save_dir)\n",
        "\n",
        "\n",
        "\n",
        "##--------------------------------------------------------------------------------------------------------\n",
        "class Hamiltonian_Conv3D(Conv3D):\n",
        "\n",
        "    def __init__(self, filters, kernel_size, kernel_3=None, kernel_4=None, activation=None, **kwargs):\n",
        "\n",
        "        self.rank = 7               # Dimension of the kernel\n",
        "        self.num_filters = filters  # Number of filter in the convolution layer\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')\n",
        "        self.kernel_3 = kernel_3    # Weights from original potential\n",
        "        self.kernel_4 = kernel_4    # Weights from interaction\n",
        "\n",
        "        super(Hamiltonian_Conv3D, self).__init__(self.num_filters, self.kernel_size,\n",
        "              activation=activation, use_bias=False, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                     'should be defined. Found `None`.')\n",
        "\n",
        "        #don't use bias:\n",
        "        self.bias = None\n",
        "\n",
        "        #consider the layer built\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "        # Define nabla operator\n",
        "        weights_1 = tf.constant([[[ 3.,-1., 0.],\n",
        "                                  [-1.,-1., 0.],\n",
        "                                  [ 0., 0., 0.]],\n",
        "                                  [[-1.,-1., 0.],\n",
        "                                  [-1., 6.,-1.],\n",
        "                                  [ 0.,-1.,-1.]],\n",
        "                                 [[ 0., 0., 0.],\n",
        "                                  [ 0.,-1.,-1.],\n",
        "                                  [ 0.,-1., 3.]]])\n",
        "\n",
        "        weights_1 = tf.reshape(weights_1 , [3,3,3, 1])\n",
        "        weights_1 = tf.repeat(weights_1 , repeats=self.num_filters, axis=3)\n",
        "        #print('kernel shape of weights_1:',weights_1.get_shape())\n",
        "\n",
        "        # Define Weights for h^2/2m  (size should be same as the nabla operator)\n",
        "        weights_2 = self.add_weight(shape=weights_1.get_shape(),\n",
        "                                      initializer= 'Orthogonal',\n",
        "                                      name='kernel_h^2/2m',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        #print('kernel shape of weights_2:',weights_2.get_shape())\n",
        "\n",
        "\n",
        "        # Define the Hamiltonian kernel\n",
        "        self.kernel = weights_1*weights_2 +self.kernel_3 + self.kernel_4\n",
        "        #print('self.kernel',self.kernel.get_shape())\n",
        "\n",
        "        self.built = True\n",
        "        super(Hamiltonian_Conv3D, self).build(input_shape)\n",
        "\n",
        "    # Do the 3D convolution using the Hamiltonian kernel\n",
        "    def convolution_op(self, inputs, kernel):\n",
        "        if self.padding == \"causal\":\n",
        "            tf_padding = \"VALID\"  # Causal padding handled in `call`.\n",
        "        elif isinstance(self.padding, str):\n",
        "            tf_padding = self.padding.upper()\n",
        "        else:\n",
        "            tf_padding = self.padding\n",
        "\n",
        "\n",
        "        return tf.nn.convolution(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            strides=list(self.strides),\n",
        "            padding=tf_padding,\n",
        "            dilations=list(self.dilation_rate),\n",
        "            data_format=self._tf_data_format,\n",
        "            name=self.__class__.__name__,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self.convolution_op(inputs, self.kernel)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def DIVA3D(depth,filters=64,image_channels=1, kernel_size= args.kernel_size, use_bnorm=True):\n",
        "    layer_count = 0\n",
        "    inpt = Input(shape=(None,None,None,image_channels),name = 'input'+str(layer_count))\n",
        "\n",
        "    # Get the initial patches /initial_patches\n",
        "    initial_patches = Conv3D(filters=filters, kernel_size=(kernel_size,kernel_size,kernel_size), strides=(1,1,1),kernel_initializer='Orthogonal', padding='same',name = 'initial_patches')(inpt)\n",
        "    initial_patches = Activation('relu',name = 'initial_patch_acti')(initial_patches)\n",
        "\n",
        "\n",
        "    print(initial_patches.get_shape())\n",
        "\n",
        "    # interaction layer\n",
        "    inter = Conv3D(filters=filters, kernel_size=(kernel_size,kernel_size,kernel_size), strides=(1,1,1),kernel_initializer='Orthogonal', padding='same',name = 'interactions')(initial_patches)\n",
        "    inter = Activation('relu',name = 'interaction_acti'+str(layer_count))(inter)\n",
        "\n",
        "    print(inter.get_shape())\n",
        "\n",
        "\n",
        "    # Get contributions of the original potential in the Hamiltonian kernel\n",
        "    ori_poten_kernel = tf.keras.layers.MaxPooling3D (pool_size=(21,21,21), strides=(15,15,15), padding='same', name = 'ori_poten_ker', data_format=None )(initial_patches)\n",
        "    #print('ori_poten_kernel',ori_poten_kernel.get_shape())\n",
        "\n",
        "    # Get contributions of the interactions in the Hamiltonian kernel\n",
        "    inter_kernel = tf.keras.layers.MaxPooling3D (pool_size=(21,21,21), strides=(15,15,15), padding='same', name = 'inter_ker', data_format=None )(inter)\n",
        "    #print('inter_kernel',inter_kernel.get_shape())\n",
        "\n",
        "\n",
        "    # Get projection coefficients of the initial patches on the Hamiltonian kernel\n",
        "    x = Hamiltonian_Conv3D(filters=filters, kernel_size=(kernel_size,kernel_size,kernel_size), kernel_3 = ori_poten_kernel, kernel_4 = inter_kernel, strides=(1,1,1), activation='relu',\n",
        "                              kernel_initializer='Orthogonal', padding='same', name = 'proj_coef')(initial_patches)\n",
        "\n",
        "    #print('coef',x.get_shape())\n",
        "\n",
        "\n",
        "    # Do Thresholding (depth depends on the noise intensity)\n",
        "    for i in range(depth+10):\n",
        "      layer_count += 1\n",
        "      x = Conv3D(filters=filters, kernel_size=(kernel_size,kernel_size,kernel_size), strides=(1,1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n",
        "\n",
        "      layer_count += 1\n",
        "      x = BatchNormalization(axis=4, momentum=0.1,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n",
        "        #x = BatchNormalization(axis=4, momentum=0.0,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n",
        "\n",
        "      # Thresholding\n",
        "    x = Activation('relu',name = 'Thresholding'+str(layer_count))(x)\n",
        "\n",
        "\n",
        "    # Inverse projection\n",
        "    x = Conv3D(filters=image_channels, kernel_size=(kernel_size,kernel_size,kernel_size), strides=(1,1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'inv_trans')(x)\n",
        "\n",
        "    x = Subtract(name = 'subtract')([inpt, x])\n",
        "\n",
        "\n",
        "\n",
        "    model = Model(inputs=inpt, outputs=x)\n",
        "\n",
        "    return model\n",
        "\n",
        "##----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def findLastCheckpoint(save_dir):\n",
        "    file_list = glob.glob(os.path.join(save_dir,'model_*.hdf5'))  # get name list of all .hdf5 files\n",
        "    #file_list = os.listdir(save_dir)\n",
        "    if file_list:\n",
        "        epochs_exist = []\n",
        "        for file_ in file_list:\n",
        "            result = re.findall(\".*model_(.*).hdf5.*\",file_)\n",
        "            #print(result[0])\n",
        "            epochs_exist.append(int(result[0]))\n",
        "        initial_epoch=max(epochs_exist)\n",
        "    else:\n",
        "        initial_epoch = 0\n",
        "    return initial_epoch\n",
        "\n",
        "\n",
        "def show(x,title=None,cbar=False,figsize=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(x,interpolation='nearest',cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    if cbar:\n",
        "        plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def log(*args,**kwargs):\n",
        "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = args.lr\n",
        "    if epoch<=20:\n",
        "        lr = initial_lr\n",
        "    elif epoch<=35:\n",
        "        lr = initial_lr/10\n",
        "    elif epoch<=50:\n",
        "        lr = initial_lr/20\n",
        "    elif epoch<=60:\n",
        "        lr = initial_lr/50\n",
        "    elif epoch<=70:\n",
        "        lr = initial_lr/100\n",
        "    elif epoch<=80:\n",
        "        lr = initial_lr/200\n",
        "    else:\n",
        "        lr = initial_lr/20\n",
        "    log('current learning rate is %2.8f' %lr)\n",
        "    return lr\n",
        "\n",
        "def train_datagen(epoch_iter=500,epoch_num=5,batch_size=64,data_dir=args.train_data):\n",
        "  import random\n",
        "  import math\n",
        "\n",
        "  while(True):\n",
        "      n_count = 0\n",
        "      if n_count == 0:\n",
        "          #print(n_count)\n",
        "          xs, ys = datagenerator(data_dir)\n",
        "          assert len(xs)%args.batch_size ==0, \\\n",
        "          log('make sure the last iteration has a full batchsize, this is important if you use batch normalization!')\n",
        "          xs = xs.astype('float32')\n",
        "          ys = ys.astype('float32')\n",
        "\n",
        "          indices = list(range(xs.shape[0]))\n",
        "          n_count = 1\n",
        "      for _ in range(epoch_num):\n",
        "          np.random.shuffle(indices)    # shuffle\n",
        "          for i in range(0, len(indices), batch_size):\n",
        "              batch_x = xs[indices[i:i+batch_size]]\n",
        "              batch_y = ys[indices[i:i+batch_size]]\n",
        "\n",
        "\n",
        "              yield batch_y, batch_x\n",
        "\n",
        "\n",
        "##--------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "##--------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "patch_size, stride = 60, 1\n",
        "aug_times = 1\n",
        "num_noise_realiza = 1\n",
        "scales = [1] #, 0.9, 0.8, 0.7\n",
        "batch_size = args.batch_size\n",
        "\n",
        "\n",
        "\n",
        "def data_aug(img, mode=0):\n",
        "\n",
        "    if mode == 0:\n",
        "        return img\n",
        "    elif mode == 1:\n",
        "        return np.flipud(img)\n",
        "    elif mode == 2:\n",
        "        return np.rot90(img)\n",
        "    elif mode == 3:\n",
        "        return np.flipud(np.rot90(img))\n",
        "    elif mode == 4:\n",
        "        return np.rot90(img, k=2)\n",
        "    elif mode == 5:\n",
        "        return np.flipud(np.rot90(img, k=2))\n",
        "    elif mode == 6:\n",
        "        return np.rot90(img, k=3)\n",
        "    elif mode == 7:\n",
        "        return np.flipud(np.rot90(img, k=3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def gen_patches(file_name):\n",
        "\n",
        "    # read image\n",
        "    #img = cv2.imread(file_name, 0)  # gray scale\n",
        "    #print(\"file_name:\",file_name)\n",
        "    I = loadmat(file_name)          # the CT gray scale image\n",
        "\n",
        "    clean_img = I['img']            # the CT data\n",
        "\n",
        "\n",
        "    img= I['img_cbct']\n",
        "    h, w , d = img.shape\n",
        "\n",
        "\n",
        "    # For SR only using DIVA3D-A\n",
        "\n",
        "    img = img[0:h:2,0:w:2,0:d:2]\n",
        "    img = rescale(img, 2, anti_aliasing=False)\n",
        "   # print(img.shape)\n",
        "\n",
        "\n",
        "    patches = []\n",
        "    clean_patches = []\n",
        "\n",
        "    # data augmentation with different rotation\n",
        "    for k in range(0, aug_times):\n",
        "        mode_k=np.random.randint(0,8)\n",
        "        x_aug = data_aug(img, mode=mode_k)\n",
        "        clean_x_aug = data_aug(clean_img, mode=mode_k)\n",
        "\n",
        "        patches.append(x_aug)\n",
        "        clean_patches.append(clean_x_aug)\n",
        "\n",
        "    return clean_patches, patches\n",
        "\n",
        "\n",
        "\n",
        "def datagenerator(data_dir=args.train_data,verbose=False):\n",
        "\n",
        "    #file_list = glob.glob(data_dir+'/*.png')  # get name list of all .png files\n",
        "    file_list = glob.glob(data_dir+'/*.mat')  # get name list of all .mat files\n",
        "\n",
        "    # initrialize\n",
        "    data = []\n",
        "    data_clean = []\n",
        "\n",
        "    # generate patches\n",
        "    for i in range(len(file_list)):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            clean_patch, patch = gen_patches(file_list[i])\n",
        "\n",
        "            data.append(patch)\n",
        "            data_clean.append(clean_patch)\n",
        "\n",
        "            #if verbose:\n",
        "            #   print(str(i+1)+'/'+ str(len(file_list)) + ' is done ^_^')\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    print(\"good dim =\", data.shape)\n",
        "    # data_clean = np.array(data_clean, dtype=np.float32)\n",
        "\n",
        "    # # do for cbct data\n",
        "    data = np.array(data, dtype='float32')\n",
        "    data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],data.shape[4],1))\n",
        "    discard_n = len(data)-len(data)//batch_size*batch_size;\n",
        "    #data = np.delete(data,range(discard_n),axis = 0)\n",
        "    # #data=tf.image.adjust_contrast(data, contrast_factor=2)\n",
        "    # # do for Mct  data\n",
        "    data_clean = np.array(data_clean, dtype='float32')\n",
        "    data_clean = data_clean.reshape((data_clean.shape[0]*data_clean.shape[1],data_clean.shape[2],data_clean.shape[3],data_clean.shape[4],1))\n",
        "    discard_n = len(data_clean)-len(data_clean)//batch_size*batch_size;\n",
        "    #data_clean = np.delete(data_clean,range(discard_n),axis = 0)\n",
        "    #data_clean=tf.image.adjust_contrast(data_clean, contrast_factor=2)\n",
        "    print('^_^-training data finished-^_^')\n",
        "    print(\"bad dim =\", data.shape)\n",
        "    print(data_clean.shape)\n",
        "\n",
        "    return data_clean, data\n",
        "\n",
        "\n",
        "##---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# define loss\n",
        "def sum_squared_error(y_true, y_pred):\n",
        "    #return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "    #return K.sum(K.square(y_pred - y_true), axis=-1)/2\n",
        "    return K.sum(K.square(y_pred - y_true))/2\n",
        "\n",
        "# Loss function ssim\n",
        "#def ssim_loss(y_true, y_pred):\n",
        "    #return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # model selection\n",
        "    model = DIVA3D(depth=20,filters=64,image_channels=1,use_bnorm=True)\n",
        "    model.summary()\n",
        "\n",
        "    # load the last model in matconvnet style\n",
        "    initial_epoch = findLastCheckpoint(save_dir=save_dir)\n",
        "    if initial_epoch > 0:\n",
        "        print('resuming by loading epoch %03d'%initial_epoch)\n",
        "        model = DIVA3D(depth=20,filters=64,image_channels=1,use_bnorm=True)\n",
        "       # model = load_model(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch), compile=False)\n",
        "        model.load_weights(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch))\n",
        "        log('load trained model architecture')\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=Adam(0.001),\n",
        "                  loss= tf.keras.losses.MeanSquaredError(), #tf.keras.losses.CosineSimilarity (axis=-1, reduction=\"auto\", name=\"cosine_similarity\"), loss=ssim_loss,\n",
        "                  #metrics=[ssim_loss, 'accuracy'])\n",
        "\n",
        "                  metrics=[tf.keras.metrics.MeanSquaredError(),\n",
        "                           tf.keras.metrics.RootMeanSquaredError(),\n",
        "                           tf.keras.metrics.MeanSquaredLogarithmicError(),\n",
        "                           tf.keras.metrics.MeanAbsoluteError(),\n",
        "                           sum_squared_error])\n",
        "\n",
        "    # tf.keras.metrics.MeanAbsolutePercentageError(), tf.keras.metrics.CosineSimilarity(name=\"cosine_similarity\", dtype=None, axis=-1),\n",
        "    # tf.keras.metrics.LogCoshError(),\n",
        "\n",
        "    # use call back functions\n",
        "    checkpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'),\n",
        "                verbose=1, save_weights_only=False, period=10)\n",
        "    csv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    history = model.fit(train_datagen(batch_size=args.batch_size),\n",
        "                steps_per_epoch=700, epochs=args.epoch, verbose=1, initial_epoch=initial_epoch,\n",
        "                callbacks=[checkpointer,csv_logger,lr_scheduler])\n",
        "\n",
        "\n",
        "##---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    # plot loss functions\n",
        "    # list all data in history\n",
        "    #print(history.history.keys())\n",
        "    # summarize history for loss\n",
        "   # plt.plot((history.history['loss']))\n",
        "    #plt.title('model loss')\n",
        "   # plt.ylabel('loss')\n",
        "    #plt.xlabel('epoch')\n",
        "   # plt.legend(['train'], loc='upper right')\n",
        "   # plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb6DFrtqYc6F"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "mount_file_id": "1zuUcgw3w9TljqOJpoH5u9Hm6GL3-HZ4g",
      "authorship_tag": "ABX9TyPkiRn7j5AO21aCPCyMyI/q",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}